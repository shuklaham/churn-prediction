{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "There is a telecom company that offers phone and internet services. There is a problem: some of our customers are churning. We would like to build a model that can identify the customers that are likely to churn. We have collected a dataset about our customers: what type of services they use, how much they paid, and how long they stayed with us. We also know who canceled their contracts and stopped using our services (churned). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's in this section\n",
    "\n",
    "In this notebook, we are going to select our final model. We will make predictions on test data and report evaluation metrics on the same.\n",
    "\n",
    "We are then going to save the model `Pickle`. We are then going to create a web service that uses the model to make predictions. We are then going to use `Docker` to package our web service. Then  we can run it on the host machine â€” laptop (regardless of the OS) or any public cloud provider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usual imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "# plt.style.use('seaborn')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from graphviz import Source\n",
    "from IPython.display import SVG,display\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# helper functions\n",
    "from churn_prediction_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df_train_full_explore\n",
    "%store -r df_train_full\n",
    "%store -r df_train\n",
    "%store -r df_val\n",
    "%store -r df_test\n",
    "\n",
    "%store -r y_train_full\n",
    "%store -r y_train\n",
    "%store -r y_val\n",
    "%store -r y_test\n",
    "\n",
    "%store -r categorical_features\n",
    "%store -r numerical_features\n",
    "\n",
    "%store -r X_train_full_scaled\n",
    "%store -r dv_full_scaled\n",
    "%store -r standard_scalar_full_data\n",
    "%store -r feature_names\n",
    "\n",
    "%store -r X_train_full_scaled\n",
    "%store -r X_train_full_not_scaled\n",
    "%store -r X_train_scaled\n",
    "%store -r X_train_not_scaled\n",
    "%store -r X_val_scaled\n",
    "%store -r X_val_not_scaled\n",
    "%store -r X_test_scaled\n",
    "%store -r X_test_not_scaled\n",
    "\n",
    "%store -r evaluation_metrics\n",
    "%store -r f_scorer\n",
    "\n",
    "%store -r phase_one_model_to_evaluation_metrics_df\n",
    "%store -r model_to_mean_evaluation_metrics_with_smote_df\n",
    "%store -r baseline_performance_metrics_df\n",
    "%store -r model_to_evaluation_metrics_with_feature_selection_df\n",
    "%store -r phase_one_metrics_collector_map\n",
    "%store -r model_to_evaluation_metrics_with_smote_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model selection\n",
    "We will go with logistic regression model with L1 regularization and C value equal to 0.1 as it has highest f1.5 value of 0.688061 on training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state= 7)\n",
    "X_train_full_scaled_oversampled, y_train_full_oversampled = sm.fit_sample(X_train_full_scaled, y_train_full)\n",
    "\n",
    "final_lr_model = LogisticRegression(solver='liblinear', random_state= 42, C= 0.1, penalty= 'l1')\n",
    "final_lr_model.fit(X_train_full_scaled_oversampled, y_train_full_oversampled)\n",
    "\n",
    "y_test_proba = final_lr_model.predict_proba(X_test_scaled)\n",
    "y_test_scores = y_test_proba[:, 1]\n",
    "y_test_pred = (y_test_scores > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>f1.5</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final Logistic Regression Model</td>\n",
       "      <td>0.691285</td>\n",
       "      <td>0.626768</td>\n",
       "      <td>0.858719</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.504378</td>\n",
       "      <td>0.756565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model_name      f1.5        f1   roc_auc    recall  \\\n",
       "0  Final Logistic Regression Model  0.691285  0.626768  0.858719  0.827586   \n",
       "\n",
       "   precision  accuracy  \n",
       "0   0.504378  0.756565  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_metrics_on_test_set_map = defaultdict(list)\n",
    "performance_metrics_on_test_set_map['model_name'] = ['Final Logistic Regression Model']\n",
    "for metric in evaluation_metrics:\n",
    "    if metric == 'f1.5':\n",
    "        metric_value = fbeta_score(y_test, y_test_pred, beta=1.5)\n",
    "    elif metric == 'f1':\n",
    "        metric_value = f1_score(y_test, y_test_pred)\n",
    "    elif metric == 'roc_auc':\n",
    "        metric_value = roc_auc_score(y_test, y_test_scores)\n",
    "    elif metric == 'recall':\n",
    "        metric_value = recall_score(y_test, y_test_pred)\n",
    "    elif metric == 'precision':\n",
    "        metric_value = precision_score(y_test, y_test_pred)\n",
    "    elif metric == 'accuracy':\n",
    "        metric_value = accuracy_score(y_test, y_test_pred)\n",
    "    performance_metrics_on_test_set_map[metric].append(metric_value)\n",
    "\n",
    "pd.DataFrame(performance_metrics_on_test_set_map)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model has `F-beta` score of 0.691285."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Using Pickle to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "with open('churn-model-development.bin', 'wb') as f_out:\n",
    "    pickle.dump((dv_full_scaled, final_lr_model), f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Flask and Docker "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets run docker container:\n",
    "\n",
    "`docker run -it -p 9696:9696 churn-prediction:latest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = {\n",
    "    'customerid': '879-zkjof',\n",
    "    'gender': 'male',\n",
    "    'seniorcitizen': 0,\n",
    "    'partner': 'no',\n",
    "    'dependents': 'no',\n",
    "    'tenure': 41,\n",
    "    'phoneservice': 'yes',\n",
    "    'multiplelines': 'no',\n",
    "    'internetservice': 'dsl',\n",
    "    'onlinesecurity': 'yes',\n",
    "    'onlinebackup': 'no',\n",
    "    'deviceprotection': 'no',\n",
    "    'techsupport': 'yes',\n",
    "    'streamingtv': 'yes',\n",
    "    'streamingmovies': 'no',\n",
    "    'contract': 'one_year',\n",
    "    'paperlessbilling': 'no',\n",
    "    'paymentmethod': 'bank_transfer_(automatic)',\n",
    "    'monthlycharges': 79.85,\n",
    "    'totalcharges': 320.75,\n",
    "}\n",
    "\n",
    "\n",
    "import requests\n",
    "url = 'http://localhost:9696/predict'\n",
    "response = requests.post(url, json=customer)\n",
    "result = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'churn': False, 'churn_probability': 0.11721333734732876}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
