{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "There is a telecom company that offers phone and internet services. There is a problem: some of our customers are churning. We would like to build a model that can identify the customers that are likely to churn. We have collected a dataset about our customers: what type of services they use, how much they paid, and how long they stayed with us. We also know who canceled their contracts and stopped using our services (churned). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to discuss thee evaluation metrics and prepare data for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usual imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "# helper functions\n",
    "from churn_prediction_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df_train_full_explore\n",
    "%store -r df_train_full\n",
    "%store -r df_train\n",
    "%store -r df_val\n",
    "%store -r df_test\n",
    "\n",
    "%store -r y_train_full\n",
    "%store -r y_train\n",
    "%store -r y_val\n",
    "%store -r y_test\n",
    "\n",
    "%store -r categorical_features\n",
    "%store -r numerical_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics\n",
    "We have imbalanced dataset. However, imbalance is moderate. Approximately 26% of the data points represent customers that have churned. Using accuracy as a evaluation metric won't be wise thing to do for the problem at hand. Positive class in this problem is the user that is going to churn. These are the users who are going to leave the app. Our model will identify these users. \n",
    "\n",
    "1. False positive in this problem signifies that a user is predicted as churned but it is actually not. \n",
    "2. False negative in this problem signifies that a user is predicted as not churned but it is actually churned.\n",
    "\n",
    "Precision takes into account #1 above. Recall takes into account #2. Lets make an assumption about the problem from business perspective: \n",
    "\n",
    "*We wish to ensure that we don't lag behind in identifying churned users. In the process of doing so, we are fine with identifying some users as churned but actually they are not (False positive).*\n",
    "\n",
    "We care more about recall in this problem. Keeping above in mind, we will focus on F score as our evaluation metric. We will calculate F score at different `beta` values. Two beta values will be considered : 1 and 1.5. These are going to be our primary metrics. Besides, F-score, we will also calculate roc-auc, precision, recall and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluation_metrics = ['f1.5', 'f1', 'roc_auc', 'recall', 'precision', 'accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_scorer = make_scorer(fbeta_score, beta=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare input data for model training and collect all feature names\n",
    "res = get_input_data_matrix(df_train_full, categorical_features, numerical_features)\n",
    "X_train_full_scaled = res['input_data_matrix']\n",
    "dv_full_scaled = res['dict_vectorizer']\n",
    "standard_scalar_full_data = res['standard_scalar']\n",
    "feature_names = res['feature_names']\n",
    "\n",
    "res = get_input_data_matrix(df_train_full, categorical_features, numerical_features, scaling_required = False)\n",
    "X_train_full_not_scaled = res['input_data_matrix']\n",
    "dv_full_not_scaled = res['dict_vectorizer']\n",
    "\n",
    "res = get_input_data_matrix(df_train, categorical_features, numerical_features)\n",
    "X_train_scaled = res['input_data_matrix']\n",
    "dv_scaled = res['dict_vectorizer']\n",
    "standard_scalar = res['standard_scalar']\n",
    "\n",
    "res = get_input_data_matrix(df_train, categorical_features, numerical_features, scaling_required = False)\n",
    "X_train_not_scaled = res['input_data_matrix']\n",
    "dv_not_scaled = res['dict_vectorizer']\n",
    "\n",
    "res = get_input_data_matrix(df_val, categorical_features, numerical_features, scaling_required = True, \n",
    "                            is_training_data= False, dict_vectorizer = dv_scaled, \n",
    "                            standard_scalar = standard_scalar)\n",
    "X_val_scaled = res['input_data_matrix']\n",
    "\n",
    "res = get_input_data_matrix(df_val, categorical_features, numerical_features, scaling_required = False, \n",
    "                            is_training_data= False, dict_vectorizer = dv_not_scaled)\n",
    "X_val_not_scaled = res['input_data_matrix']\n",
    "\n",
    "res = get_input_data_matrix(df_test, categorical_features, numerical_features, scaling_required = True, \n",
    "                            is_training_data= False, dict_vectorizer = dv_full_scaled, \n",
    "                            standard_scalar = standard_scalar_full_data)\n",
    "X_test_scaled = res['input_data_matrix']\n",
    "\n",
    "res = get_input_data_matrix(df_test, categorical_features, numerical_features, scaling_required = False, \n",
    "                            is_training_data= False, dict_vectorizer = dv_full_not_scaled)\n",
    "X_test_not_scaled = res['input_data_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'X_train_full_scaled' (ndarray)\n",
      "Stored 'dv_full_scaled' (DictVectorizer)\n",
      "Stored 'standard_scalar_full_data' (StandardScaler)\n",
      "Stored 'feature_names' (list)\n",
      "Stored 'X_train_full_scaled' (ndarray)\n",
      "Stored 'X_train_full_not_scaled' (ndarray)\n",
      "Stored 'X_train_scaled' (ndarray)\n",
      "Stored 'X_train_not_scaled' (ndarray)\n",
      "Stored 'X_val_scaled' (ndarray)\n",
      "Stored 'X_val_not_scaled' (ndarray)\n",
      "Stored 'X_test_scaled' (ndarray)\n",
      "Stored 'X_test_not_scaled' (ndarray)\n",
      "Stored 'X_test_scaled' (ndarray)\n",
      "Stored 'X_test_not_scaled' (ndarray)\n",
      "Stored 'evaluation_metrics' (list)\n",
      "Stored 'f_scorer' (_PredictScorer)\n"
     ]
    }
   ],
   "source": [
    "%store X_train_full_scaled\n",
    "%store dv_full_scaled\n",
    "%store standard_scalar_full_data\n",
    "%store feature_names\n",
    "\n",
    "%store X_train_full_scaled\n",
    "%store X_train_full_not_scaled\n",
    "%store X_train_scaled\n",
    "%store X_train_not_scaled\n",
    "%store X_val_scaled\n",
    "%store X_val_not_scaled\n",
    "%store X_test_scaled\n",
    "%store X_test_not_scaled\n",
    "\n",
    "%store X_test_scaled\n",
    "%store X_test_not_scaled\n",
    "\n",
    "%store evaluation_metrics\n",
    "%store f_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
